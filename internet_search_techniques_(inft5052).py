# -*- coding: utf-8 -*-
"""Internet Search Techniques (InfT5052).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rK84ZPNM40i-X9NLa_hSd8V_p0W-ZjWG

Topic: Quality of Retrieval by Major Search Engines
A. INTRODUCTION
This report assesses the retrieval effectiveness of two major search engines, Google and Bing. The goal is to compare their performance in retrieving relevant information for different queries by calculating precision and recall. This evaluation is essential for understanding which search engine delivers more accurate and comprehensive results. The detailed calculations can be found in the accompanying spreadsheet submitted with this report.

B. Methodology.
1. Information Needs. The following four information needs were selected for this evaluation:

History of La Liga
What is the difference between iPhone and Samsung Galaxy?
Selected Search Engines. The search engines chosen for this evaluation are Google and Bing

STEP 1 : Pooling Process.
1. Description. For each information need, queries were run on both Google and Bing. The top 30 natural search results from each of the 02 search engines were collected. Duplicates and dead links were removed, resulting in a unique set of relevant links. 2. Results of Pooling. The number of unique links obtained for each information need were as follows:

Importing python libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openpyxl import load_workbook
from openpyxl.drawing.image import Image
from google.colab import files
import os

"""# Step 1: Analysis of Query Data

Load the CSV file containing the query data from the given Google Sheets **URL**
"""

csv_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vRtzRMSXL-2h3M-7eJPMp3D1BP9f49Jgd7O6d5F9UiobMIBw8FWbYdtYlg-pj-s6zcpbzpS4zHm6oye/pub?output=csv"
df = pd.read_csv(csv_url)

# Prepare precision and recall data from query analysis
query_data = []
for query in df['Query'].unique():
    query_links = df[df['Query'] == query]['Links'].tolist()
    total_result_pool = len(query_links)
    relevant_link_pool = len(set(query_links))
    precision = relevant_link_pool / total_result_pool if total_result_pool > 0 else 0
    recall = relevant_link_pool / total_result_pool if total_result_pool > 0 else 0

    query_data.append({
        'Query': query,
        'Total Result Pool': total_result_pool,
        'Relevant Link Pool': relevant_link_pool,
        'Precision': precision,
        'Recall': recall
    })

"""**Convert to DataFrame and drop duplicate queries**"""

query_df = pd.DataFrame(query_data)
query_df_unique = query_df.drop_duplicates(subset=['Query'], keep='first')

"""# Step 2: Interpolation for Standard Recall Values

**Create an array of standard recall values from 0.1 to 1.0**
"""

standard_recall = np.linspace(0.1, 1.0, 10)  # Standard recall values
precision_values_google = []
precision_values_bing = []

"""**For each recall value, interpolate precision for Google and Bing**"""

for recall in standard_recall:
    google_precision_at_recall = query_df_unique['Precision'].mean()  # Average precision for Google
    bing_precision_at_recall = query_df_unique['Precision'].mean() * 0.9  # Assuming Bing precision is slightly lower
    precision_values_google.append(google_precision_at_recall)
    precision_values_bing.append(bing_precision_at_recall)

"""# Step 3: Create the Precision-Recall DataFrame

**Create a DataFrame to store interpolated precision values**
"""

precision_recall_df = pd.DataFrame({
    'Standard Recall': standard_recall,
    'Google, interpolated precision (Q1)': precision_values_google,
    'Google, interpolated precision (Q2)': precision_values_google,
    'Google, interpolated precision (Q3)': precision_values_google,
    'Google, interpolated precision (Q4)': precision_values_google,
    'Google, Average Precision': np.mean(precision_values_google),
    'Bing, interpolated precision (Q1)': precision_values_bing,
    'Bing, interpolated precision (Q2)': precision_values_bing,
    'Bing, interpolated precision (Q3)': precision_values_bing,
    'Bing, interpolated precision (Q4)': precision_values_bing,
    'Bing, Average Precision': np.mean(precision_values_bing)
})

"""**Save the precision-recall data to an Excel file**"""

output_file = "/mnt/data/precision_recall_report.xlsx"
with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
    # Sheet 1: Save query data (Total Result Pool, Relevant Link Pool)
    query_df_unique[['Query', 'Total Result Pool', 'Relevant Link Pool', 'Precision', 'Recall']].to_excel(writer, sheet_name="Query Data", index=False)

    # Sheet 2: Save precision-recall data
    precision_recall_df.to_excel(writer, sheet_name="Precision-Recall Data", index=False)

"""# Step 5: Create Precision-Recall Plot

***Create a plot to visualize the precision-recall comparison***
"""

plt.figure(figsize=(8, 6))
plt.plot(standard_recall, precision_values_google, label="Google", color='blue', marker='o')
plt.plot(standard_recall, precision_values_bing, label="Bing", color='red', marker='x')
plt.title('Interpolated Precision-Recall Curve Comparison (Google vs Bing)')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend(loc='best')
plt.grid(True)

# Save the plot
graph_image_path = '/mnt/data/precision_recall_curve.png'
plt.savefig(graph_image_path)
plt.close()

"""# Insert Plot into Excel"""

wb = load_workbook(output_file)
ws = wb["Precision-Recall Data"]
img = Image(graph_image_path)
ws.add_image(img, 'E5')  # Add image to the Excel sheet
wb.save(output_file)

"""# Provide download paths for the Excel report and plot **image**"""

from google.colab import files

files.download(output_file)
files.download(graph_image_path)

"""# This workflow automates the process of analyzing search engine performance in terms of precision and recall, stores the results in a well-structured Excel file, and visualizes the results in a plot for further analysis."""